{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "kernel_List = [12, 4, 4, 4, 4, 4]\n",
    "channel_List = [128, 256, 512, 512, 512, 400]\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, kernel_sz, padding, stride = 2) -> None:\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channel, out_channel, kernel_sz, stride, padding)\n",
    "        self.bn = nn.BatchNorm2d(out_channel)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout()\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn(self.conv(x)))\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "def get_convBlocks(in_channel):\n",
    "    layerNum = len(kernel_List)\n",
    "    blocks = []\n",
    "    blocks.append(ConvBlock(in_channel, channel_List[0], kernel_List[0], int(kernel_List[0] / 2 - 1)))\n",
    "    for i in range(1, layerNum):\n",
    "        blocks.append(ConvBlock(channel_List[i-1], channel_List[i], kernel_List[i], int(kernel_List[i] / 2 - 1)))\n",
    "    return blocks\n",
    "\n",
    "class DeepFold(nn.Module):\n",
    "    def __init__(self, in_channel) -> None:\n",
    "        super().__init__()\n",
    "        self.convLayer = nn.Sequential(*get_convBlocks(in_channel))\n",
    "    \n",
    "    # [batch_size, 3, 256, 256]\n",
    "    def forward(self, x):\n",
    "        # [batch_size, 400, 4, 4]\n",
    "        x = self.convLayer(x)\n",
    "        # [batch_size, 400, 4]\n",
    "        x = torch.diagonal(x, dim1=2, dim2=3)\n",
    "        # [batch_size, 400]\n",
    "        x = torch.mean(x, dim= 2)\n",
    "\n",
    "        normValue = torch.norm(x, dim = 1) # norm_value [batch_size]\n",
    "        # print(normValue.shape)\n",
    "        # [400, batch_size]  除法要求最后一维要和norm_value维度匹配\n",
    "        x = x.permute(1, 0)\n",
    "        # [400, batch_size] 已经正则化\n",
    "        x = torch.div(x, normValue)\n",
    "\n",
    "        # [batch_size, 400]\n",
    "        x = x.permute(1, 0)\n",
    "        return x\n",
    "\n",
    "    # def hook(self, layer: nn.Module, input: torch.tensor, output)\n",
    "\n",
    "# outputList = []\n",
    "# def hook(self, layer: nn.Module,  output: torch.tensor):\n",
    "#     outputList.append(output)\n",
    "\n",
    "x = torch.rand(2, 3, 256, 256)\n",
    "\n",
    "model = DeepFold(3)\n",
    "\n",
    "# for layer in model.convLayer:\n",
    "#     layer.register_forward_hook(hook)\n",
    "\n",
    "y = model(x)\n",
    "\n",
    "print(torch.norm(y, dim = 1).shape)\n",
    "\n",
    "# for ele in outputList:\n",
    "#     print(ele.shape)\n",
    "\n",
    "# print(model)\n",
    "# print(help(model))\n",
    "# print(len(list(model.named_modules())))\n",
    "# for name,_ in model.convLayer.named_modules():\n",
    "#     print(name)\n",
    "#     print('-'*60)\n",
    "\n",
    "# √\n",
    "# print(x.shape)\n",
    "# for layer in model.convLayer:\n",
    "#     x = layer(x)\n",
    "#     print(x.shape)\n",
    "#     print('-'*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6000, 0.8000],\n",
      "        [0.3846, 0.9231],\n",
      "        [0.6000, 0.8000]])\n",
      "tensor([ 5., 13.,  5.])\n",
      "tensor([[ 3.,  5.,  3.],\n",
      "        [ 4., 12.,  4.]])\n",
      "tensor([[0.6000, 0.3846, 0.6000],\n",
      "        [0.8000, 0.9231, 0.8000]])\n",
      "tensor([[0.6000, 0.8000],\n",
      "        [0.3846, 0.9231],\n",
      "        [0.6000, 0.8000]])\n",
      "tensor([1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "x = torch.tensor(\n",
    "    [[3, 4],\n",
    "    [5, 12],\n",
    "    [3, 4]],dtype=torch.float32)\n",
    "# print(x.dtype)\n",
    "print(F.normalize(x))\n",
    "\n",
    "normV = torch.norm(x, dim = 1)\n",
    "print(normV)\n",
    "x = x.permute(1, 0)\n",
    "print(x)\n",
    "res = torch.div(x, normV)\n",
    "print(res)\n",
    "res = res.permute(1, 0)\n",
    "print(res)\n",
    "normV2 = torch.norm(res, dim = 1)\n",
    "print(normV2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcy(x: torch.tensor, k:int):\n",
    "    return x**(-2*k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pretfm(torch.nn.Module):\n",
    "    def __init__(self, in_channel) -> None:\n",
    "        super().__init__()\n",
    "        self.in_channel = in_channel\n",
    "\n",
    "    def forward(self, x: torch.tensor):\n",
    "\n",
    "        y = torch.rand(self.in_channel, 256, 256)\n",
    "\n",
    "        for i in range(1, self.in_channel+1):\n",
    "            y[i-1] = funcy(x, i)\n",
    "        x = y\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channel = 3\n",
    "import torchvision.transforms as T\n",
    "train_tfm = T.Compose(\n",
    "    [\n",
    "        T.Resize((256, 256)),\n",
    "        # 取逆矩阵 扩充channel\n",
    "        # Pretfm(in_channel),\n",
    "        # 是否需要数据增强 保留一个问号\n",
    "        # 层归一化\n",
    "        # nn.LayerNorm((in_channel, 256, 256))\n",
    "    ]\n",
    ")\n",
    "# t = nn.LayerNorm((in_channel, 256, 256))\n",
    "# # x = torch.rand(1, 188, 188)\n",
    "# x = torch.tensor([[[1,1],\n",
    "#                     [2,2]\n",
    "#                     ]\n",
    "#                     ], dtype=torch.float32)\n",
    "# output = train_tfm(x)\n",
    "# print(output)\n",
    "# # print(output.shape)\n",
    "# print(t(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class Train_set(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, dir, id_list, tfm) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.tensor_list = []\n",
    "        for id, label in id_list:\n",
    "            # 在蛋白质数据库文件查找 id.npy\n",
    "            feature = torch.from_numpy(np.load(dir+id+\".npy\", allow_pickle=True))\n",
    "            feature = torch.unsqueeze(feature, 0)\n",
    "            self.tensor_list.append((feature,\n",
    "                                        label)\n",
    "                                        )\n",
    "        self.tfm = tfm\n",
    "\n",
    "    def __getitem__(self, idx :int):\n",
    "        y = self.tensor_list[idx][0]\n",
    "        y = self.tfm(y)\n",
    "        label = torch.float64(self.tensor_list[idx][1])\n",
    "        return y, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tensor_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('d1a0pa2', '0'), ('d2a0ua1', '0'), ('d3a04a_', '0'), ('d5a0ya1', '0'), ('d5a0ya2', '0'), ('d1a1ia1', '0'), ('d1a1va2', '0'), ('d2a14a1', '0'), ('d2a19a2', '0'), ('d2a1jb1', '0')]\n",
      "torch.Size([1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "dir = \"../distance_matrix/distance_matrix_inf/\"\n",
    "id_path = \"../pair/pair_bool/d1a0aa_.txt\"\n",
    "id_list = []\n",
    "\n",
    "with open(id_path, \"r\") as f_r:\n",
    "    while True:\n",
    "        lines = f_r.readline()\n",
    "        if not lines:\n",
    "            break\n",
    "        line = lines.split('\\n')[0].split('\\t')\n",
    "        id_list.append((line[0], line[1]))\n",
    "\n",
    "# print(len(id_list))\n",
    "\n",
    "dataset = Train_set(dir, id_list[:10], train_tfm)\n",
    "print(id_list[:10])\n",
    "print(dataset[0][0].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "data = np.load(\"../distance_matrix/distance_matrix_inf/d1a0pa2.npy\", allow_pickle=True)\n",
    "data = torch.from_numpy(data)\n",
    "print(data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取左侧一列id 对应的右侧id_list\n",
    "def get_id_list(pair_path):\n",
    "    id_list = []\n",
    "    with open(pair_path, \"r\") as f_r:\n",
    "        while True:\n",
    "            lines = f_r.readline()\n",
    "            if not lines:\n",
    "                break\n",
    "            line1= lines.split('\\t')[0]\n",
    "            line2 = lines.split('\\t')[1].split(\"\\n\")[0]\n",
    "            id_list.append((line1, line2))\n",
    "    return id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取id对应的distance_matrix\n",
    "def get_feature(data_path, tfm):\n",
    "    feature = torch.from_numpy(np.load(data_path, allow_pickle=True))\n",
    "    feature = torch.unsqueeze(feature, 0)\n",
    "    feature = feature.to(torch.float)\n",
    "    feature = tfm(feature)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63, 9, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "lis = [3, 2,63,9]\n",
    "lis.sort(reverse=True)\n",
    "print(lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(posi_cosList, nega_cosList, K = 10, m = 0.1):\n",
    "    posi_cosList.sort() # 升序排序 选最小\n",
    "    nega_cosList.sort(reverse=True) # 降序排序 选最大\n",
    "    posi_cos = posi_cosList[0] # 只选取一个正例\n",
    "    loss = 0\n",
    "    for i in range(K):\n",
    "        nega_cos = nega_cosList[i]\n",
    "        loss += max(0, nega_cos - posi_cos + m)\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "theSelecTrainList = np.load(\"/home/wngys/lab/DeepFold/pair/train.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'theSelecTrainList' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/wngys/lab/DeepFold/Code/Net.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244617461534349227d/home/wngys/lab/DeepFold/Code/Net.ipynb#ch0000013vscode-remote?line=27'>28</a>\u001b[0m pair_dir \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/home/wngys/lab/DeepFold/pair/train_pair_bool_90/\u001b[39m\u001b[39m\"\u001b[39m  \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244617461534349227d/home/wngys/lab/DeepFold/Code/Net.ipynb#ch0000013vscode-remote?line=28'>29</a>\u001b[0m data_dir \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/home/wngys/lab/DeepFold/distance_matrix_r/distance_matrix_mine_r_3/\u001b[39m\u001b[39m\"\u001b[39m \n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244617461534349227d/home/wngys/lab/DeepFold/Code/Net.ipynb#ch0000013vscode-remote?line=30'>31</a>\u001b[0m trainIDlist \u001b[39m=\u001b[39m theSelecTrainList[:\u001b[39m64\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244617461534349227d/home/wngys/lab/DeepFold/Code/Net.ipynb#ch0000013vscode-remote?line=32'>33</a>\u001b[0m leftTrain_ds \u001b[39m=\u001b[39m LeftTrainSet(data_dir, trainIDlist, train_tfm)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244617461534349227d/home/wngys/lab/DeepFold/Code/Net.ipynb#ch0000013vscode-remote?line=33'>34</a>\u001b[0m leftTrain_dl \u001b[39m=\u001b[39m DataLoader(leftTrain_ds, batch_size, shuffle \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'theSelecTrainList' is not defined"
     ]
    }
   ],
   "source": [
    "# 训练过程\n",
    "#/home/wngys/lab/DeepFold/Code\n",
    "from model import *\n",
    "from data import *\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import cosine_similarity\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "DFold_model = DeepFold(in_channel = 3)\n",
    "DFold_model.to(device)\n",
    "\n",
    "train_tfm = build_transform(in_channel = 3)\n",
    "\n",
    "# print(train_tfm)\n",
    "optimizer = torch.optim.SGD(DFold_model.parameters(), lr = 1e-3)\n",
    "\n",
    "total_epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "resume_dir = None\n",
    "if resume_dir is not None:\n",
    "    pass\n",
    "else:\n",
    "    st_epoch = 0\n",
    "\n",
    "pair_dir = \"/home/wngys/lab/DeepFold/pair/train_pair_bool_90/\"  \n",
    "data_dir = \"/home/wngys/lab/DeepFold/distance_matrix_r/distance_matrix_mine_r_3/\" \n",
    "\n",
    "trainIDlist = theSelecTrainList[:64]\n",
    "\n",
    "leftTrain_ds = LeftTrainSet(data_dir, trainIDlist, train_tfm)\n",
    "leftTrain_dl = DataLoader(leftTrain_ds, batch_size, shuffle = True)\n",
    "# print(leftTrain_ds[0][1].shape)\n",
    "\n",
    "for epoch in range(st_epoch, total_epochs):\n",
    "    # 遍历左侧一列集合每一个Protein ID\n",
    "    DFold_model.train()\n",
    "\n",
    "    for IDBatch, feature1 in leftTrain_dl:\n",
    "\n",
    "        feature1 = feature1.to(device)\n",
    "        fingerpbatch = DFold_model(feature1)\n",
    "\n",
    "        for batch_idx in range(len(IDBatch)):\n",
    "            id_list = get_id_list(pair_dir + IDBatch[batch_idx] +\".txt\")\n",
    "            # id_list = get_id_list(\"/home/wngys/lab/DeepFold/test_d1a0aa_Pair.txt\")\n",
    "            fingerpvec1 = fingerpbatch[batch_idx]\n",
    "            # feature1 = get_feature(data_dir + id + \".npy\", train_tfm)\n",
    "   \n",
    "            # print(feature1)\n",
    "            train_ds = Train_set(data_dir, id_list, train_tfm)\n",
    "            # print(train_ds[0][0])\n",
    "            train_dl = DataLoader(train_ds, batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "\n",
    "            IDtotalLoss = 0\n",
    "            for feature2, label in train_dl:\n",
    "                feature2 = feature2.to(device)\n",
    "                label = label.to(device)\n",
    "                fingerpvec2 = DFold_model(feature2)\n",
    "                \n",
    "                posi_vec_list = []\n",
    "                nega_vec_list = []\n",
    "\n",
    "                for number_inbatch in range(fingerpvec2.shape[0]):\n",
    "                    if label[number_inbatch] == 0:\n",
    "                        nega_vec_list.append(fingerpvec2[number_inbatch])\n",
    "                    elif label[number_inbatch] == 1:\n",
    "                        posi_vec_list.append(fingerpvec2[number_inbatch])\n",
    "                    else:\n",
    "                        print(\"ERROR\")\n",
    "\n",
    "                posi_cos_smi_list = []\n",
    "                nega_cos_smi_list = []\n",
    "\n",
    "                for posi_vec in posi_vec_list:\n",
    "                    posi_cos_smi_list.append(F.cosine_similarity(fingerpvec1, posi_vec, dim = 0))\n",
    "\n",
    "                for nega_vec in nega_vec_list:\n",
    "                    nega_cos_smi_list.append(F.cosine_similarity(fingerpvec1, nega_vec, dim = 0))\n",
    "\n",
    "                # 计算batch Loss\n",
    "                loss = compute_loss(posi_cos_smi_list, nega_cos_smi_list)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward(retain_graph=True)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                IDtotalLoss += loss\n",
    "\n",
    "            print(f\"Epoch: {epoch} | queryID: {IDBatch[batch_idx]} | avg_loss: {IDtotalLoss / len(train_dl):.4f}\")\n",
    "\n",
    "        # DFold_model.eval()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9487, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "test_t = torch.tensor([1, 1], dtype=torch.float64)\n",
    "test_t2 = torch.tensor([2, 4], dtype = torch.float64)\n",
    "\n",
    "print(F.cosine_similarity(test_t, test_t2,dim = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "4\n",
      "('5', '8', '3', '1') tensor([5, 8, 3, 1])\n",
      "<class 'tuple'>\n",
      "4\n",
      "('7', '6', '4', '2') tensor([7, 6, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "class test_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, left, right) -> None:\n",
    "        super().__init__()\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.left[index], self.right[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.left)\n",
    "\n",
    "left = ['1', '2', '3', '4', '5', '6', '7', '8']\n",
    "right = []\n",
    "for i in range(8):\n",
    "    right.append(torch.tensor(i+1))\n",
    "# print(right)\n",
    "\n",
    "ds = test_dataset(left, right)\n",
    "# print(ds[5])\n",
    "dl = torch.utils.data.DataLoader(ds, batch_size=4, shuffle = True)\n",
    "\n",
    "for x, y in dl:\n",
    "    print(type(x))\n",
    "    print(len(x))\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "from model import *\n",
    "from data import *\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "\n",
    "def read_data():\n",
    "    data_dir = \"/home/wngys/lab/DeepFold/distance_matrix_r/distance_matrix_mine_r_3\"\n",
    "    data_dict = {}\n",
    "    # print(os.listdir(data_dir)[:10])\n",
    "    for file_name in os.listdir(data_dir):\n",
    "        # print(file_name)\n",
    "        file_path = os.path.join(data_dir, file_name)\n",
    "        data = np.load(file_path, allow_pickle=True)\n",
    "        ID = file_name.split('.')[0]\n",
    "        data_dict[ID] = data\n",
    "        break\n",
    "\n",
    "    fileName = \"/home/wngys/lab/DeepFold/distance_matrix_r/matrix_data.npy\"\n",
    "    \n",
    "    np.save(fileName, data_dict)\n",
    "\n",
    "read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = \"/home/wngys/lab/DeepFold/distance_matrix_r/matrix_data.npy\"\n",
    "d = np.load(fileName, allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 285, 285)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['d3m2pa1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('miniconda38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "474a727007314fe946f45bbc9b266c6bb0e4e19682495744a6293558354c7c6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
