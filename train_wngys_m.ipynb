{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4, 1, 2, 3\"\n",
    "device_ids = [0, 1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_List = [12, 4, 4, 4, 4, 4]\n",
    "channel_List = [128, 256, 512, 512, 512, 400]\n",
    "\n",
    "class ConvBlock(nn.Module):   \n",
    "    def __init__(self, in_channel, out_channel, kernel_sz, padding, stride = 2) -> None:\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channel, out_channel, kernel_sz, stride, padding)\n",
    "        self.bn = nn.BatchNorm2d(out_channel)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout()\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn(self.conv(x)))\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "def get_convBlocks(in_channel):\n",
    "    layerNum = len(kernel_List)\n",
    "    blocks = []\n",
    "    blocks.append(ConvBlock(in_channel, channel_List[0], kernel_List[0], int(kernel_List[0] / 2 - 1)))\n",
    "    for i in range(1, layerNum):\n",
    "        blocks.append(ConvBlock(channel_List[i-1], channel_List[i], kernel_List[i], int(kernel_List[i] / 2 - 1)))\n",
    "    return blocks\n",
    "\n",
    "class DeepFold(nn.Module):\n",
    "    def __init__(self, in_channel) -> None:\n",
    "        super().__init__()\n",
    "        self.convLayer = nn.Sequential(*get_convBlocks(in_channel))\n",
    "    def forward(self, x):\n",
    "        x = self.convLayer(x)\n",
    "        x = torch.diagonal(x, dim1=2, dim2=3) # [batch_size, 400, 4]\n",
    "        x = torch.mean(x, dim= 2)  # [batch_size, 400]\n",
    "        x = F.normalize(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transform():\n",
    "    train_tfm = T.Compose(\n",
    "        [\n",
    "            T.Resize((256, 256)),\n",
    "            # T.Normalize(mean=[0.0068, 0.0003, 2.3069e-05], std=[0.0140, 0.0015, 0.0002])\n",
    "            T.Normalize(mean=[0.0660], std=[0.0467])\n",
    "        ]\n",
    "    )\n",
    "    return train_tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_set(torch.utils.data.Dataset):\n",
    "    def __init__(self, dict_data, id_list, tfm) -> None:\n",
    "        super().__init__()\n",
    "        self.tensor_list = []\n",
    "        for id, label in id_list:\n",
    "            feature = torch.from_numpy(dict_data[id])\n",
    "            self.tensor_list.append((feature, label))\n",
    "        self.tfm = tfm\n",
    "\n",
    "    def __getitem__(self, idx :int):\n",
    "        x = self.tensor_list[idx][0]\n",
    "        x = x.to(torch.float)\n",
    "        x = self.tfm(x)\n",
    "        label = self.tensor_list[idx][1]\n",
    "        return x,label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tensor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Max_margin_loss(nn.Module):\n",
    "    def __init__(self, K, m) -> None:\n",
    "        super().__init__()\n",
    "        self.K = K\n",
    "        self.m = m\n",
    "   \n",
    "    def forward(self, fpvec1, fpvec2):\n",
    "        # vec1 [1,400]\n",
    "        # vec2 [64,400]\n",
    "        pos_vec = fpvec2[:6]\n",
    "        neg_vec = fpvec2[6:]\n",
    "        fpvec1_6 = fpvec1.repeat(6, 1)\n",
    "        fpvec1_58 = fpvec1.repeat(58,1)\n",
    "        pos_cos = F.cosine_similarity(fpvec1_6, pos_vec, dim=-1).view(6, 1)\n",
    "        neg_cos = F.cosine_similarity(fpvec1_58, neg_vec, dim=-1).view(1, 58)\n",
    "\n",
    "        diff = neg_cos - pos_cos + self.m\n",
    "        loss = torch.sum(diff[diff>=0])\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取左侧一列id 对应的右侧id_list\n",
    "def get_id_list(pair_path):\n",
    "    id_list = []\n",
    "    with open(pair_path, \"r\") as f_r:\n",
    "        while True:\n",
    "            lines = f_r.readline()\n",
    "            if not lines:\n",
    "                break\n",
    "            line1= lines.split('\\t')[0]\n",
    "            line2 = lines.split('\\t')[1].split(\"\\n\")[0]\n",
    "            id_list.append((line1, line2))\n",
    "    return id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 获取id对应的distance_matrix\n",
    "def get_feature(dict_data, id, tfm):\n",
    "    feature = torch.from_numpy(dict_data[id])\n",
    "    feature = feature.to(torch.float)\n",
    "    feature = tfm(feature)\n",
    "    feature = feature.unsqueeze(0)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DFold_model = DeepFold(in_channel = 1)\n",
    "DFold_model = nn.DataParallel(DFold_model, device_ids).to(device)\n",
    "train_tfm = build_transform()\n",
    "optimizer = torch.optim.SGD(DFold_model.parameters(), lr = 1e-3, momentum=0.9)\n",
    "lossF = Max_margin_loss(K = 10, m = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_epoch = 0\n",
    "total_epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "train_loss_ls = []\n",
    "valid_acc_ls = []\n",
    "train_acc_ls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainIDlist = np.load(\"/home/wngys/lab/DeepFold/pair/train.npy\", allow_pickle=True)\n",
    "random.shuffle(trainIDlist)\n",
    "trainIDlist = trainIDlist[:400]\n",
    "validIDlist = np.load(\"/home/wngys/lab/DeepFold/pair/valid.npy\", allow_pickle=True)\n",
    "random.shuffle(validIDlist)\n",
    "validIDlist = validIDlist[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_dir = \"/home/wngys/lab/DeepFold/pair/train_pair_bool_90/\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_data = np.load(\"/home/wngys/lab/DeepFold/distance_matrix_r/matrix_data_1.npy\", allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_test(mode):\n",
    "    valid_pair_dir = \"/home/wngys/lab/DeepFold/pair/pair_bool_90/\" \n",
    "    DFold_model.eval()\n",
    "    K = 5\n",
    "  \n",
    "    acc_num = 0\n",
    "\n",
    "    if mode == 0:\n",
    "        IDlist = trainIDlist[:100]\n",
    "    else:\n",
    "        IDlist = validIDlist\n",
    "\n",
    "    for id in IDlist:\n",
    "        feature1 = get_feature(dict_data, id, train_tfm)\n",
    "        feature1 = feature1.to(device)\n",
    "\n",
    "        id_list = get_id_list(valid_pair_dir + id +\".txt\")\n",
    "        train_ds = Train_set(dict_data, id_list, train_tfm)\n",
    "        train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "        with torch.no_grad():\n",
    "            fpvec1 = DFold_model(feature1)\n",
    "        topList = []\n",
    "        for feature2, label in train_dl:\n",
    "            feature2 = feature2.to(device)\n",
    "            with torch.no_grad():\n",
    "                fpvec2 = DFold_model(feature2)\n",
    "            fpvec1_bs = fpvec1.repeat(fpvec2.shape[0], 1)\n",
    "            cos_sim = F.cosine_similarity(fpvec1_bs, fpvec2, dim=-1)\n",
    "            \n",
    "            for i in range(fpvec2.shape[0]):\n",
    "                topList.append((cos_sim[i], label[i]))\n",
    "        topList.sort(reverse=True)\n",
    "        acc_flag = False\n",
    "        for _, label in topList[:K]:\n",
    "            if label == '1':\n",
    "                acc_flag = True\n",
    "                break\n",
    "        if acc_flag:\n",
    "            acc_num += 1\n",
    "\n",
    "    acc = acc_num / len(IDlist)\n",
    "    print(f\"acc: {acc} | acc_num: {acc_num} | total: {len(IDlist)}\")\n",
    "    DFold_model.train()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(st_epoch, total_epochs):\n",
    "    # 遍历左侧一列集合每一个Protein ID\n",
    "    DFold_model.train()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    for id_idx, id in enumerate(trainIDlist):\n",
    "        feature1 = get_feature(dict_data, id, train_tfm)\n",
    "        feature1 = feature1.to(device)\n",
    "        id_list = get_id_list(pair_dir + id +\".txt\")\n",
    "        train_ds = Train_set(dict_data, id_list, train_tfm)\n",
    "        train_dl = DataLoader(train_ds, batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "        IDtotalLoss = 0\n",
    "        for feature2, _ in train_dl:\n",
    "            fingerpvec1 = DFold_model(feature1)\n",
    "            feature2 = feature2.to(device)\n",
    "            fingerpvec2 = DFold_model(feature2)\n",
    "            loss = lossF(fingerpvec1, fingerpvec2)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            IDtotalLoss += loss.item()\n",
    "        \n",
    "        total_train_loss += IDtotalLoss\n",
    "\n",
    "        print(f\"Epoch: {epoch} | IDidx: {id_idx} | queryID: {id} | avg_loss: {IDtotalLoss / len(train_ds):.4f} | pair_num: {len(train_ds)}\")\n",
    "\n",
    "        if  id_idx % 200 == 0:\n",
    "            print(\"-----train_Set-----\")\n",
    "            train_acc = valid_test(mode=0)\n",
    "            print(\"-----valid_Set-----\")\n",
    "            valid_acc = valid_test(mode=1)\n",
    "\n",
    "            valid_acc_ls.append(valid_acc)\n",
    "            train_acc_ls.append(train_acc)\n",
    "\n",
    "    train_loss_ls.append(total_train_loss)\n",
    "    print(f\"Epoch: {epoch} | total_loss: {total_train_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testOnDatabase():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('miniconda38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "474a727007314fe946f45bbc9b266c6bb0e4e19682495744a6293558354c7c6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
